{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI6zyIM20Kw4",
        "outputId": "8ad96f7c-aed8-4c0b-bac4-1f074cf224d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tapas-table-parsing\n",
            "  Downloading tapas_table_parsing-0.0.1.dev0-py3-none-any.whl (195 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▊                              | 10 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |█████                           | 30 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 40 kB 26.2 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 51 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 61 kB 21.9 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 71 kB 22.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 81 kB 23.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 92 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 102 kB 25.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 112 kB 25.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 122 kB 25.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 133 kB 25.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 143 kB 25.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 153 kB 25.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 163 kB 25.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 174 kB 25.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 184 kB 25.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 194 kB 25.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 195 kB 25.8 MB/s \n",
            "\u001b[?25hCollecting frozendict==1.2\n",
            "  Downloading frozendict-1.2.tar.gz (2.6 kB)\n",
            "Collecting tf-slim~=1.1.0\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 41.4 MB/s \n",
            "\u001b[?25hCollecting scikit-learn~=0.22.1\n",
            "  Downloading scikit_learn-0.22.2.post1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 49.2 MB/s \n",
            "\u001b[?25hCollecting pandas~=1.0.0\n",
            "  Downloading pandas-1.0.5-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 59.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow-probability==0.10.1\n",
            "  Downloading tensorflow_probability-0.10.1-py2.py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 46.2 MB/s \n",
            "\u001b[?25hCollecting tf-models-official~=2.2.0\n",
            "  Downloading tf_models_official-2.2.2-py2.py3-none-any.whl (711 kB)\n",
            "\u001b[K     |████████████████████████████████| 711 kB 69.7 MB/s \n",
            "\u001b[?25hCollecting nltk~=3.5\n",
            "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 45.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow~=2.2.0\n",
            "  Downloading tensorflow-2.2.3-cp37-cp37m-manylinux2010_x86_64.whl (516.4 MB)\n",
            "\u001b[K     |██▉                             | 46.4 MB 61.1 MB/s eta 0:00:08"
          ]
        }
      ],
      "source": [
        "! pip install tapas-table-parsing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B10C0Yz6gQyD"
      },
      "outputs": [],
      "source": [
        "! gsutil cp gs://tapas_models/2020_10_07/tapas_wikisql_sqa_inter_masklm_large.zip . && unzip tapas_wikisql_sqa_inter_masklm_large.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnUjDlLqDd3m"
      },
      "outputs": [],
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "import os \n",
        "import shutil\n",
        "import csv\n",
        "import pandas as pd\n",
        "import IPython\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aml6oLFl1dSt"
      },
      "outputs": [],
      "source": [
        "from tapas.utils import tf_example_utils\n",
        "from tapas.protos import interaction_pb2\n",
        "from tapas.utils import number_annotation_utils\n",
        "from tapas.scripts import prediction_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKfxspnVFPsc"
      },
      "outputs": [],
      "source": [
        "os.makedirs('results/sqa/tf_examples', exist_ok=True)\n",
        "os.makedirs('results/sqa/model', exist_ok=True)\n",
        "with open('results/sqa/model/checkpoint', 'w') as f:\n",
        "  f.write('model_checkpoint_path: \"model.ckpt-0\"')\n",
        "for suffix in ['.data-00000-of-00001', '.index', '.meta']:\n",
        "  shutil.copyfile(f'tapas_wikisql_sqa_inter_masklm_large/model.ckpt{suffix}', f'results/sqa/model/model.ckpt-0{suffix}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RlvgDAmCNtP"
      },
      "outputs": [],
      "source": [
        "max_seq_length = 512\n",
        "vocab_file = \"tapas_wikisql_sqa_inter_masklm_large/vocab.txt\"\n",
        "config = tf_example_utils.ClassifierConversionConfig(\n",
        "    vocab_file=vocab_file,\n",
        "    max_seq_length=max_seq_length,\n",
        "    max_column_id=max_seq_length,\n",
        "    max_row_id=max_seq_length,\n",
        "    strip_column_names=False,\n",
        "    add_aggregation_candidates=False,\n",
        ")\n",
        "converter = tf_example_utils.ToClassifierTensorflowExample(config)\n",
        "\n",
        "def convert_interactions_to_examples(tables_and_queries):\n",
        "  \"\"\"Calls Tapas converter to convert interaction to example.\"\"\"\n",
        "  for idx, (table, queries) in enumerate(tables_and_queries):\n",
        "    interaction = interaction_pb2.Interaction()\n",
        "    for position, query in enumerate(queries):\n",
        "      question = interaction.questions.add()\n",
        "      question.original_text = query\n",
        "      question.id = f\"{idx}-0_{position}\"\n",
        "    for header in table[0]:\n",
        "      interaction.table.columns.add().text = header\n",
        "    for line in table[1:]:\n",
        "      row = interaction.table.rows.add()\n",
        "      for cell in line:\n",
        "        row.cells.add().text = cell\n",
        "    number_annotation_utils.add_numeric_values(interaction)\n",
        "    for i in range(len(interaction.questions)):\n",
        "      try:\n",
        "        yield converter.convert(interaction, i)\n",
        "      except ValueError as e:\n",
        "        print(f\"Can't convert interaction: {interaction.id} error: {e}\")\n",
        "        \n",
        "def write_tf_example(filename, examples):\n",
        "  with tf.io.TFRecordWriter(filename) as writer:\n",
        "    for example in examples:\n",
        "      writer.write(example.SerializeToString())\n",
        "\n",
        "def predict(table_data, queries):\n",
        "  table = [list(map(lambda s: s.strip(), row.split(\"|\"))) \n",
        "           for row in table_data.split(\"\\n\") if row.strip()]\n",
        "  examples = convert_interactions_to_examples([(table, queries)])\n",
        "  write_tf_example(\"results/sqa/tf_examples/test.tfrecord\", examples)\n",
        "  write_tf_example(\"results/sqa/tf_examples/random-split-1-dev.tfrecord\", [])\n",
        "  \n",
        "  !python -m tapas.run_task_main \\\n",
        "    --task=\"SQA\" \\\n",
        "    --output_dir=\"results\" \\\n",
        "    --noloop_predict \\\n",
        "    --test_batch_size={len(queries)} \\\n",
        "    --tapas_verbosity=\"ERROR\" \\\n",
        "    --compression_type= \\\n",
        "    --init_checkpoint=\"tapas_wikisql_sqa_inter_masklm_large/model.ckpt\" \\\n",
        "    --bert_config_file=\"tapas_wikisql_sqa_inter_masklm_large/bert_config.json\" \\\n",
        "    --mode=\"predict\" 2> error\n",
        "\n",
        "\n",
        "  results_path = \"results/sqa/model/test_sequence.tsv\"\n",
        "  all_coordinates = []\n",
        "  df = pd.DataFrame(table[1:], columns=table[0])\n",
        "  display(IPython.display.HTML(df.to_html(index=False)))\n",
        "  print()\n",
        "  with open(results_path) as csvfile:\n",
        "    reader = csv.DictReader(csvfile, delimiter='\\t')\n",
        "    for row in reader:\n",
        "      coordinates = prediction_utils.parse_coordinates(row[\"answer_coordinates\"])\n",
        "      all_coordinates.append(coordinates)\n",
        "      answers = ', '.join([table[row + 1][col] for row, col in coordinates])\n",
        "      position = int(row['position'])\n",
        "      print(\">\", queries[position])\n",
        "      print(answers)\n",
        "  return all_coordinates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIE7bTJMVuSh"
      },
      "outputs": [],
      "source": [
        "table = \"\"\"\n",
        "Pos | No | Driver               | Team                           | Laps | Time/Retired | Grid | Points\n",
        "1   | 32 | Patrick Carpentier   | Team Player's                  | 87   | 1:48:11.023  | 1    | 22    \n",
        "2   | 1  | Bruno Junqueira      | Newman/Haas Racing             | 87   | +0.8 secs    | 2    | 17    \n",
        "3   | 3  | Paul Tracy           | Team Player's                  | 87   | +28.6 secs   | 3    | 14\n",
        "4   | 9  | Michel Jourdain, Jr. | Team Rahal                     | 87   | +40.8 secs   | 13   | 12\n",
        "5   | 34 | Mario Haberfeld      | Mi-Jack Conquest Racing        | 87   | +42.1 secs   | 6    | 10\n",
        "6   | 20 | Oriol Servia         | Patrick Racing                 | 87   | +1:00.2      | 10   | 8 \n",
        "7   | 51 | Adrian Fernandez     | Fernandez Racing               | 87   | +1:01.4      | 5    | 6\n",
        "8   | 12 | Jimmy Vasser         | American Spirit Team Johansson | 87   | +1:01.8      | 8    | 5\n",
        "9   | 7  | Tiago Monteiro       | Fittipaldi-Dingman Racing      | 86   | + 1 Lap      | 15   | 4\n",
        "10  | 55 | Mario Dominguez      | Herdez Competition             | 86   | + 1 Lap      | 11   | 3\n",
        "11  | 27 | Bryan Herta          | PK Racing                      | 86   | + 1 Lap      | 12   | 2\n",
        "12  | 31 | Ryan Hunter-Reay     | American Spirit Team Johansson | 86   | + 1 Lap      | 17   | 1\n",
        "13  | 19 | Joel Camathias       | Dale Coyne Racing              | 85   | + 2 Laps     | 18   | 0\n",
        "14  | 33 | Alex Tagliani        | Rocketsports Racing            | 85   | + 2 Laps     | 14   | 0\n",
        "15  | 4  | Roberto Moreno       | Herdez Competition             | 85   | + 2 Laps     | 9    | 0\n",
        "16  | 11 | Geoff Boss           | Dale Coyne Racing              | 83   | Mechanical   | 19   | 0\n",
        "17  | 2  | Sebastien Bourdais   | Newman/Haas Racing             | 77   | Mechanical   | 4    | 0\n",
        "18  | 15 | Darren Manning       | Walker Racing                  | 12   | Mechanical   | 7    | 0\n",
        "19  | 5  | Rodolfo Lavin        | Walker Racing                  | 10   | Mechanical   | 16   | 0\n",
        "\"\"\"\n",
        "ques = [\"what were the drivers names?\",\n",
        "      \"of these, which points did patrick carpentier and bruno junqueira score?\",\n",
        "      \"who scored higher?\"]\n",
        "result = predict(table, ques)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hX6yy-t9kZNd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
